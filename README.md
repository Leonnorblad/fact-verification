# fact-verification
Fact verification tools can be used to check a text's truthfulness. The task consists of three subtasks, document retrieval, sentence selection, and claim verification. In this project, a model was trained to perform the claim verification task using generated data. The data was generated by feeding scraped Wikipedia articles together with instructions to generate a true or false statement in a prompt to ChatGPT 3 turbo (via API). The article was used as evidence, giving the model a paragraph of text that contains the truth. The ChatGPT response was used as a claim, either a true statement meaning it aligns with the evidence, or a false statement, meaning it contradicts the evidence. The evidence and claim were then embedded by using BERT-small. A model containing bidirectional LSTM layers was used to distinguish between false and true claims. The model was able to classify the validation samples with a macro average F1-score of $0.80$. After evaluating the model using custom inputs it was found that it is sensitive to the term 'not'. The reason for this could be due to an overrepresentation of 'not' in the false claims.
